#!/usr/bin/env python3
import argparse
import datetime as dt
import hashlib
import json
import math
import re
from collections import Counter, defaultdict
from pathlib import Path
from typing import Dict, List, Tuple

ROOT = Path("/Users/avrohom/Downloads/journeyatlas")
MODEL_BLOCK_BEGIN = "// BEGIN AUTOGENERATED_LOCAL_REASONER_MODEL"
MODEL_BLOCK_END = "// END AUTOGENERATED_LOCAL_REASONER_MODEL"

DEFAULT_DATASET = ROOT / "atlas-concierge/kb/training/local_reasoner_training.jsonl"
DEFAULT_IOS_OUTPUT = ROOT / "ios-app/AtlasMasaIOS/Sources/Core/LocalReasoningEngine.swift"
DEFAULT_MACOS_OUTPUT = ROOT / "macos-app/AtlasMasaMacOS/Sources/Core/LocalReasoningEngine.swift"
DEFAULT_REPORT_OUTPUT = ROOT / "docs/ai/swift-travel-design-model-report.md"
DEFAULT_COMPAT_REPORT_OUTPUT = ROOT / "docs/ai/local-reasoner-model-report.md"
DEFAULT_ARTIFACT_DIR = ROOT / "artifacts/swift-travel-design-model"

TRAVEL_DESIGN_LABELS = [
    "travel_design_execution",
    "travel_design_revenue",
    "travel_design_resilience",
    "travel_design_recovery",
    "travel_design_strategy",
    "travel_design_journey_ops",
    "travel_design_systems",
    "travel_design_emergency_command",
    "travel_design_human_problem_solving",
    "travel_design_tech_innovation",
]

LEGACY_LABEL_MAP = {
    "execution_now": "travel_design_execution",
    "revenue_focus": "travel_design_revenue",
    "resilience_safety": "travel_design_resilience",
    "health_recovery": "travel_design_recovery",
    "strategy_long_horizon": "travel_design_strategy",
    "travel_ops": "travel_design_journey_ops",
    "technical_debug": "travel_design_systems",
    "emergency_response": "travel_design_emergency_command",
    "crisis_planning": "travel_design_emergency_command",
    "crisis_management": "travel_design_emergency_command",
    "incident_command": "travel_design_emergency_command",
    "human_problem_solving": "travel_design_human_problem_solving",
    "problem_solving_human": "travel_design_human_problem_solving",
    "tech_innovation": "travel_design_tech_innovation",
    "innovation_tech": "travel_design_tech_innovation",
}

LABEL_BRIEF = {
    "travel_design_execution": "Travel design execution protocol",
    "travel_design_revenue": "Travel design commercial growth lane",
    "travel_design_resilience": "Travel design continuity and safety lane",
    "travel_design_recovery": "Travel design recovery and regulation lane",
    "travel_design_strategy": "Travel design long-horizon architecture lane",
    "travel_design_journey_ops": "Travel design journey logistics lane",
    "travel_design_systems": "Travel design systems diagnostics lane",
    "travel_design_emergency_command": "Travel design emergency command lane",
    "travel_design_human_problem_solving": "Travel design human problem-solving optimization lane",
    "travel_design_tech_innovation": "Travel design technology innovation systems lane",
}

DEFAULT_NEXT_ACTION = {
    "travel_design_execution": "Design one 15-minute field move now, execute it, and log the outcome.",
    "travel_design_revenue": "Design one direct revenue move today and schedule a same-day close attempt.",
    "travel_design_resilience": "Design continuity checks now: power, comms, legal fallback, and response path.",
    "travel_design_recovery": "Design a low-load recovery block with one controlled novelty exposure, then run a short reflection log.",
    "travel_design_strategy": "Design the next strategic milestone and include a weekly novelty-plus-reflection review loop.",
    "travel_design_journey_ops": "Design route legality, one novel segment, and a familiar overnight fallback before movement.",
    "travel_design_systems": "Design a narrow diagnostic test, isolate root cause, and patch with verification.",
    "travel_design_emergency_command": "Design an emergency command protocol now: triage, stabilize, communicate, and route to safe harbor.",
    "travel_design_human_problem_solving": "Design biological and environmental conditions for high cognition, then run one deliberate problem-solving drill.",
    "travel_design_tech_innovation": "Design one digital-physical innovation experiment with explicit safety constraints and measurable outcomes.",
}

SEED_KEYWORDS = {
    "travel_design_execution": [
        "execute",
        "today",
        "immediate",
        "action",
        "focus",
        "block",
        "momentum",
        "delivery",
        "travel_design",
        "ביצוע",
        "מיקוד",
        "משימה",
        "תיעדוף",
        "מדד",
    ],
    "travel_design_revenue": [
        "revenue",
        "cash",
        "client",
        "sales",
        "pricing",
        "income",
        "profit",
        "offer",
        "pipeline",
        "הכנסה",
        "לקוחות",
        "תמחור",
        "עסקה",
        "צמיחה",
    ],
    "travel_design_resilience": [
        "safety",
        "fallback",
        "emergency",
        "risk",
        "continuity",
        "backup",
        "resilience",
        "comms",
        "power",
        "חוסן",
        "גיבוי",
        "חירום",
        "בטיחות",
        "רציפות",
    ],
    "travel_design_recovery": [
        "recovery",
        "stress",
        "fatigue",
        "sleep",
        "regulation",
        "burnout",
        "health",
        "cognitive",
        "rest",
        "novelty",
        "reflection",
        "neuroplasticity",
        "cognitive_reserve",
        "brain_aging",
        "התאוששות",
        "עומס",
        "נוירופלסטיות",
        "רפלקציה",
        "הזדקנות_מוחית",
    ],
    "travel_design_strategy": [
        "strategy",
        "capital",
        "mission",
        "horizon",
        "scale",
        "roadmap",
        "wealth",
        "design",
        "systems",
        "reflection_loop",
        "perspective_shift",
        "אסטרטגיה",
        "הון",
        "תזה",
        "ארכיטקטורה",
        "ראייה_ארוכת_טווח",
    ],
    "travel_design_journey_ops": [
        "route",
        "travel",
        "journey",
        "overnight",
        "logistics",
        "mobility",
        "legal",
        "service",
        "vehicle",
        "novelty_exposure",
        "micro_adventure",
        "familiar_fallback",
        "מסלול",
        "נסיעה",
        "תפעול_שטח",
        "חניון_לילה",
        "חלופה_חוקית",
    ],
    "travel_design_systems": [
        "debug",
        "error",
        "api",
        "deploy",
        "auth",
        "passkey",
        "incident",
        "logs",
        "fix",
        "תקלה",
        "אימות",
        "לוגים",
        "ניפוי",
        "תיקון",
    ],
    "travel_design_emergency_command": [
        "emergency",
        "crisis",
        "triage",
        "incident",
        "command",
        "evacuation",
        "response",
        "containment",
        "rescue",
        "safe_harbor",
        "חירום",
        "משבר",
        "טריאז",
        "פיקוד",
        "פינוי",
        "חילוץ",
        "ייצוב",
    ],
    "travel_design_human_problem_solving": [
        "problem_solving",
        "human_factors",
        "cognitive_flexibility",
        "metacognition",
        "decision_quality",
        "biological_conditions",
        "environmental_conditions",
        "attention",
        "sleep",
        "recovery",
        "פתרון_בעיות",
        "גורמי_אנוש",
        "גמישות_קוגניטיבית",
        "מטא_קוגניציה",
        "קבלת_החלטות",
        "תנאים_ביולוגיים",
        "תנאים_סביבתיים",
    ],
    "travel_design_tech_innovation": [
        "innovation",
        "systems_thinking",
        "rapid_prototyping",
        "simulation",
        "hardware",
        "software",
        "digital",
        "physical",
        "reliability_engineering",
        "experimentation",
        "חדשנות",
        "מערכות",
        "אב_טיפוס",
        "סימולציה",
        "הנדסה",
        "דיגיטלי",
        "פיזי",
    ],
}

SYNTHETIC_PROMPTS = {
    "travel_design_execution": [
        "Travel design brief: I need immediate execution with one controlled output block.",
        "Design one action now that compounds progress before today ends.",
        "I need travel design delivery mode, not extra planning.",
        "תכל'ס, צריך מהלך ביצוע אחד ל-15 הדקות הקרובות עם מדד הצלחה ברור.",
        "מצב עומס: תכנן בלוק מיקוד קצר, מדיד, וניתן לביצוע מיידי.",
    ],
    "travel_design_revenue": [
        "Travel design business brief: prioritize one revenue move for today.",
        "Design a direct client and pricing sequence that can close this week.",
        "Money pressure is real, I need a travel design revenue sprint.",
        "השוק הישראלי צפוף; צריך מהלך הכנסה חד וברור מול לקוח יעד כבר היום.",
        "בנה רצף תמחור-שיחה-סגירה שמייצר תזרים ולא רק חשיפה.",
    ],
    "travel_design_resilience": [
        "Design continuity stack for tonight: power, comms, legal fallback, and safety.",
        "Travel design resilience mode: plan for breakdown and recovery path.",
        "Need safety-first design under uncertainty and restricted control.",
        "תרחיש קצה: תקלה בלי קליטה. בנה פרוטוקול חוסן עם גיבוי תקשורת ונקודת מפלט חוקית.",
        "בתרבות שטח ישראלית צריך גם מהירות תגובה וגם משמעת בטיחותית.",
    ],
    "travel_design_recovery": [
        "Travel design recovery mode: lower cognitive load and protect consistent output.",
        "Stress is high and energy is low, design a controlled recovery plan.",
        "Design a low-friction system so I can recover and still move forward.",
        "Design novelty windows that are safe and brief, followed by reflection to reduce cognitive rigidity.",
        "Use travel design to alternate familiar anchors with novel inputs to support neuroplastic adaptation.",
        "Build a brain-aging slowdown protocol: movement, novelty, recovery sleep, and reflective journaling.",
        "שלב חשיפה לחדשנות בקצב בטוח עם רפלקציה כתובה כדי לשמור גמישות קוגניטיבית.",
        "החלף בין עוגן מוכר לחוויה חדשה כדי לתמוך בנוירופלסטיות לאורך זמן.",
    ],
    "travel_design_strategy": [
        "Design long-horizon strategy that aligns daily actions with wealth trajectory.",
        "Travel design architecture for mission, scale, and durable financial stability.",
        "Need strategic design for next quarter and next 10 years.",
        "Design a reflection system that converts travel novelty into better strategic decisions.",
        "Build weekly novelty + debrief cycles so old problems are seen from new angles.",
        "בנה תזת מסע רב-שנתית עם אבני דרך להון, חוסן, והשפעה חברתית.",
        "תרגם חידוש יומי לרפלקציה אסטרטגית שבועית ולהחלטות טובות יותר.",
    ],
    "travel_design_journey_ops": [
        "Design legal journey operations with safe overnight and service checkpoints.",
        "Travel design route planning for heavy-usage mobility work.",
        "Need journey logistics design with continuity backups.",
        "Design routes with controlled novelty and reliable familiar fallbacks to improve adaptability.",
        "Plan a micro-adventure block that triggers reflection without destabilizing operations.",
        "תכנן מסלול עם נקודת חידוש, נקודת עגינה מוכרת, וחלופת לינה חוקית.",
        "שלב תפעול מסע ישראלי: עומסים, תדלוק, תחזוקה, וחלון התאוששות.",
    ],
    "travel_design_systems": [
        "Travel design systems incident: auth flow fails and needs verified fix.",
        "Design a debugging path for deployment error and unstable callback.",
        "Need diagnostics-first patch process with rollback safety.",
        "נתח תקלה בשיטת בידוד משתנים, אימות לוגים, ותיקון הפיך.",
        "שמור על סטנדרט הנדסי: בדיקה, תיקוף, ותיעוד לפני פריסה מחדש.",
    ],
    "travel_design_emergency_command": [
        "Emergency command brief: define triage, containment, communication, and extraction in order.",
        "Crisis planning request: prepare immediate response and 24-hour continuity plan.",
        "Emergency management mode: assign roles, escalation thresholds, and safe-harbor routing.",
        "תרחיש חירום: בנה פקודת מצב ברורה עם טריאז', ייצוב, תקשורת ופינוי.",
        "במשבר תפעולי דרוש נוהל פיקוד קצר עם אחריות, לוחות זמנים, ונתיב חילוץ.",
    ],
    "travel_design_human_problem_solving": [
        "Human problem-solving brief: optimize biological and environmental conditions before complex decisions.",
        "Design a cognitive performance protocol for stress, uncertainty, and high-stakes judgment.",
        "Build adaptive skill growth with deliberate drills, reflection, and metacognitive review.",
        "שפר יכולת פתרון בעיות אנושית: שינה, עומס קוגניטיבי, סביבת עבודה ורפלקציה.",
        "בנה שגרת גורמי אנוש לפתרון בעיות מורכבות תחת לחץ.",
    ],
    "travel_design_tech_innovation": [
        "Tech innovation brief: design a digital + physical prototype loop with reliability gates.",
        "Create an innovation protocol that moves from hypothesis to safe field validation quickly.",
        "Need systems-level problem solving for product architecture across software and hardware.",
        "תכנן חדשנות טכנולוגית דיגיטלית-פיזית עם ניסוי מהיר ובקרת סיכונים.",
        "בנה מסלול פיתוח הנדסי: הנחת יסוד, אב טיפוס, מדידה, שיפור.",
    ],
}


def normalize_label(label: str) -> str:
    normalized = re.sub(r"[\s\-]+", "_", (label or "").strip().lower())
    if normalized in LEGACY_LABEL_MAP:
        return LEGACY_LABEL_MAP[normalized]
    if normalized in TRAVEL_DESIGN_LABELS:
        return normalized
    if normalized.startswith("travel_design_"):
        return normalized
    return "travel_design_strategy"


def tokenize(text: str) -> List[str]:
    unigrams = [t for t in re.findall(r"[A-Za-z0-9_\u0590-\u05FF]+", text.lower()) if len(t) >= 2]
    if len(unigrams) < 2:
        return unigrams
    bigrams = [f"{a}_{b}" for a, b in zip(unigrams, unigrams[1:])]
    return unigrams + bigrams


def parse_dataset(path: Path) -> List[Dict]:
    rows = []
    for line_number, raw in enumerate(path.read_text(encoding="utf-8").splitlines(), start=1):
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        row = json.loads(line)
        prompt = str(row.get("prompt", "")).strip()
        if not prompt:
            continue
        label = normalize_label(str(row.get("label", "")).strip())
        next_action = str(row.get("next_action", "")).strip() or DEFAULT_NEXT_ACTION.get(label, DEFAULT_NEXT_ACTION["travel_design_strategy"])
        rows.append({"prompt": prompt, "label": label, "next_action": next_action, "line": line_number})
    return rows


def add_synthetic(rows: List[Dict]) -> Tuple[List[Dict], int]:
    out = list(rows)
    synthetic_count = 0
    for label in TRAVEL_DESIGN_LABELS:
        prompts = list(SYNTHETIC_PROMPTS.get(label, []))
        prompts.extend(generated_synthetic_prompts(label))
        seen = set()
        deduped_prompts = []
        for prompt in prompts:
            key = prompt.strip().lower()
            if not key or key in seen:
                continue
            seen.add(key)
            deduped_prompts.append(prompt)
        for prompt in deduped_prompts:
            out.append(
                {
                    "prompt": prompt,
                    "label": label,
                    "next_action": DEFAULT_NEXT_ACTION[label],
                    "line": -1,
                }
            )
            synthetic_count += 1
    return out, synthetic_count


def generated_synthetic_prompts(label: str) -> List[str]:
    seeds = SEED_KEYWORDS.get(label, [])
    if len(seeds) < 6:
        return []
    lane_name = label.replace("travel_design_", "").replace("_", " ")
    return [
        f"Travel design {lane_name} mode: prioritize {seeds[0]}, {seeds[1]}, and {seeds[2]} in the next decision block.",
        f"Atlas travel design request: structure {seeds[0]} with {seeds[3]} while protecting {seeds[4]} today.",
        f"I need a precise travel design lane for {seeds[0]} + {seeds[1]} + {seeds[5]}.",
        f"Build a no-fluff plan around {seeds[0]} and {seeds[2]} with one immediate action.",
        f"Design protocol now: {seeds[0]}, {seeds[1]}, {seeds[2]}, then execute and log.",
        f"Mission pressure is high; use travel design in the {lane_name} lane with {seeds[3]} and {seeds[4]}.",
        f"Generate one action path that improves {seeds[0]} without breaking {seeds[5]}.",
        f"I want a premium, concise operational brief for {seeds[0]}, {seeds[1]}, and {seeds[2]}.",
    ]


def rebalance_rows(rows: List[Dict], min_per_label: int, max_per_label: int) -> List[Dict]:
    buckets: Dict[str, List[Dict]] = defaultdict(list)
    for row in rows:
        buckets[row["label"]].append(row)

    rebalanced: List[Dict] = []
    for label in TRAVEL_DESIGN_LABELS:
        bucket = buckets.get(label, [])
        if not bucket:
            continue
        trimmed = bucket[: max(1, max_per_label)]
        rebalanced.extend(trimmed)

        needed = max(0, min_per_label - len(trimmed))
        if needed == 0:
            continue

        synthetic_pool = list(SYNTHETIC_PROMPTS.get(label, []))
        synthetic_pool.extend(generated_synthetic_prompts(label))
        if not synthetic_pool:
            synthetic_pool = [f"Travel design {label.replace('travel_design_', '').replace('_', ' ')} protocol."]

        for idx in range(needed):
            prompt = synthetic_pool[idx % len(synthetic_pool)]
            rebalanced.append(
                {
                    "prompt": prompt,
                    "label": label,
                    "next_action": DEFAULT_NEXT_ACTION[label],
                    "line": -2,
                }
            )
    return rebalanced


def collect_labels(rows: List[Dict]) -> List[str]:
    seen = {row["label"] for row in rows}
    labels = [label for label in TRAVEL_DESIGN_LABELS if label in seen]
    # ensure stable full taxonomy
    for label in TRAVEL_DESIGN_LABELS:
        if label not in labels:
            labels.append(label)
    return labels


def split_train_test(rows: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
    buckets: Dict[str, List[Dict]] = defaultdict(list)
    for row in rows:
        buckets[row["label"]].append(row)

    train, test = [], []
    for _, group in sorted(buckets.items()):
        for idx, row in enumerate(group):
            (test if idx % 5 == 0 else train).append(row)
    if not train or not test:
        return rows, []
    return train, test


def build_vocabulary(rows: List[Dict], max_vocab: int, min_token_freq: int) -> Tuple[List[str], Dict[str, int]]:
    counts = Counter()
    for row in rows:
        counts.update(tokenize(row["prompt"]))
    filtered = [(token, count) for token, count in counts.items() if count >= min_token_freq]
    filtered.sort(key=lambda item: (-item[1], item[0]))
    selected = filtered[: max(1, max_vocab)]
    return [token for token, _ in selected], dict(selected)


def compute_token_importance(rows: List[Dict], labels: List[str], vocabulary: List[str]) -> Dict[str, float]:
    vocab_set = set(vocabulary)
    per_label = {label: Counter() for label in labels}
    global_counter = Counter()
    label_totals = Counter()
    global_total = 0

    for row in rows:
        label = row["label"]
        tokens = [t for t in tokenize(row["prompt"]) if t in vocab_set]
        if not tokens:
            continue
        per_label[label].update(tokens)
        label_totals[label] += len(tokens)
        global_counter.update(tokens)
        global_total += len(tokens)

    vocab_size = max(1, len(vocabulary))
    scores: Dict[str, float] = {}
    for token in vocabulary:
        global_prob = (global_counter[token] + 1.0) / (global_total + vocab_size)
        best = 0.0
        for label in labels:
            label_prob = (per_label[label][token] + 1.0) / (label_totals[label] + vocab_size)
            ratio = abs(math.log(label_prob / global_prob))
            if ratio > best:
                best = ratio
        freq_boost = math.log1p(global_counter[token])
        scores[token] = best * (1.0 + 0.1 * freq_boost)
    return scores


def prune_vocabulary(vocabulary: List[str], token_freq: Dict[str, int], importance: Dict[str, float], target: int) -> List[str]:
    if target <= 0 or len(vocabulary) <= target:
        return vocabulary
    ranked = sorted(
        vocabulary,
        key=lambda token: (-importance.get(token, 0.0), -token_freq.get(token, 0), token),
    )
    kept = ranked[:target]
    return kept


def train_weights(
    rows: List[Dict],
    labels: List[str],
    vocabulary: List[str],
    prior_uniform_mix: float,
) -> Tuple[List[float], List[List[float]]]:
    label_index = {label: idx for idx, label in enumerate(labels)}
    vocab_index = {token: idx for idx, token in enumerate(vocabulary)}
    label_count = len(labels)
    vocab_size = len(vocabulary)

    doc_counts = [0] * label_count
    token_counts = [[0] * vocab_size for _ in range(label_count)]
    label_token_totals = [0] * label_count

    for row in rows:
        li = label_index[row["label"]]
        doc_counts[li] += 1
        for token in tokenize(row["prompt"]):
            if token not in vocab_index:
                continue
            ti = vocab_index[token]
            token_counts[li][ti] += 1
            label_token_totals[li] += 1

    total_docs = max(1, len(rows))
    prior_denom = total_docs + label_count
    observed_priors = [math.log((count + 1) / prior_denom) for count in doc_counts]
    uniform_prior = math.log(1.0 / max(1, label_count))
    prior_uniform_mix = min(1.0, max(0.0, prior_uniform_mix))
    log_priors = [
        (1.0 - prior_uniform_mix) * observed + prior_uniform_mix * uniform_prior
        for observed in observed_priors
    ]

    log_likelihoods = [[0.0] * vocab_size for _ in range(label_count)]
    for li in range(label_count):
        denom = label_token_totals[li] + vocab_size
        for ti in range(vocab_size):
            log_likelihoods[li][ti] = math.log((token_counts[li][ti] + 1) / denom)
    return log_priors, log_likelihoods


def predict_label(
    prompt: str,
    labels: List[str],
    vocabulary: List[str],
    log_priors: List[float],
    log_likelihoods: List[List[float]],
    keyword_hints: List[List[str]],
    keyword_bonus: float,
) -> int:
    vocab_index = {token: idx for idx, token in enumerate(vocabulary)}
    token_hits = Counter(token for token in tokenize(prompt) if token in vocab_index)
    token_set = set(token_hits.keys())

    best_idx = 0
    best_score = -1e18
    for li, _ in enumerate(labels):
        score = log_priors[li]
        for token, count in token_hits.items():
            score += log_likelihoods[li][vocab_index[token]] * count
        hint_matches = len(token_set.intersection(set(keyword_hints[li])))
        score += hint_matches * keyword_bonus
        if score > best_score:
            best_score = score
            best_idx = li
    return best_idx


def collect_keyword_hints(rows: List[Dict], labels: List[str]) -> List[List[str]]:
    global_counts = Counter()
    per_label_counts: Dict[str, Counter] = {label: Counter() for label in labels}
    for row in rows:
        tokens = set(tokenize(row["prompt"]))
        global_counts.update(tokens)
        per_label_counts[row["label"]].update(tokens)

    hints = []
    for label in labels:
        scored = []
        for token, label_freq in per_label_counts[label].items():
            global_freq = max(1, global_counts[token])
            score = (label_freq + 0.5) / (global_freq + 1.0)
            scored.append((token, score, label_freq))
        scored.sort(key=lambda item: (-item[1], -item[2], item[0]))

        merged = list(SEED_KEYWORDS.get(label, []))
        merged.extend(token for token, _, _ in scored[:16])
        deduped = []
        seen = set()
        for token in merged:
            if token in seen:
                continue
            seen.add(token)
            deduped.append(token)
            if len(deduped) >= 20:
                break
        hints.append(deduped)
    return hints


def collect_next_actions(rows: List[Dict], labels: List[str]) -> List[str]:
    by_label: Dict[str, Counter] = {label: Counter() for label in labels}
    for row in rows:
        by_label[row["label"]].update([row["next_action"]])
    actions = []
    for label in labels:
        if by_label[label]:
            action, _ = by_label[label].most_common(1)[0]
            actions.append(action)
        else:
            actions.append(DEFAULT_NEXT_ACTION.get(label, DEFAULT_NEXT_ACTION["travel_design_strategy"]))
    return actions


def evaluate_model(
    rows: List[Dict],
    labels: List[str],
    max_vocab: int,
    min_token_freq: int,
    prune_target_vocab: int,
    prior_uniform_mix: float,
):
    train_rows, test_rows = split_train_test(rows)
    if not test_rows:
        return {
            "test_size": 0,
            "accuracy": 1.0,
            "per_label": {},
            "confusion": {},
            "vocab_size_raw": 0,
            "vocab_size_pruned": 0,
        }

    vocab_raw, freq = build_vocabulary(train_rows, max_vocab=max_vocab, min_token_freq=min_token_freq)
    importance = compute_token_importance(train_rows, labels, vocab_raw)
    vocab = prune_vocabulary(vocab_raw, token_freq=freq, importance=importance, target=prune_target_vocab)
    log_priors, log_likelihoods = train_weights(train_rows, labels, vocab, prior_uniform_mix=prior_uniform_mix)
    keyword_hints = collect_keyword_hints(train_rows, labels)

    correct = 0
    per_label = defaultdict(lambda: [0, 0])
    confusion = defaultdict(lambda: defaultdict(int))
    for row in test_rows:
        predicted_idx = predict_label(
            row["prompt"],
            labels,
            vocab,
            log_priors,
            log_likelihoods,
            keyword_hints,
            keyword_bonus=2.4,
        )
        predicted = labels[predicted_idx]
        actual = row["label"]
        confusion[actual][predicted] += 1
        per_label[actual][1] += 1
        if predicted == actual:
            correct += 1
            per_label[actual][0] += 1

    return {
        "test_size": len(test_rows),
        "accuracy": correct / max(1, len(test_rows)),
        "per_label": dict(per_label),
        "confusion": {k: dict(v) for k, v in confusion.items()},
        "vocab_size_raw": len(vocab_raw),
        "vocab_size_pruned": len(vocab),
    }


def inject_model_block(swift_path: Path, model_json: str):
    content = swift_path.read_text(encoding="utf-8")
    start = content.find(MODEL_BLOCK_BEGIN)
    end = content.find(MODEL_BLOCK_END)
    if start == -1 or end == -1 or start >= end:
        raise ValueError(f"model markers missing/invalid in {swift_path}")
    before = content[:start]
    after = content[end + len(MODEL_BLOCK_END):]
    block = (
        f"{MODEL_BLOCK_BEGIN}\n"
        f'private let defaultLocalReasoningModelJSON = #"""\n'
        f"{model_json}\n"
        f'"""#\n'
        f"{MODEL_BLOCK_END}"
    )
    swift_path.write_text(before + block + after, encoding="utf-8")


def write_report(
    report_path: Path,
    run_id: str,
    run_tag: str,
    dataset_path: Path,
    dataset_sha: str,
    sample_count: int,
    synthetic_count: int,
    labels: List[str],
    max_vocab: int,
    min_token_freq: int,
    prune_target_vocab: int,
    prior_uniform_mix: float,
    eval_summary: Dict,
    min_holdout_accuracy: float,
):
    lines = [
        "# Swift Travel Design Model Report",
        "",
        f"- Generated at (UTC): {dt.datetime.now(dt.timezone.utc).isoformat()}",
        f"- Run ID: `{run_id}`",
    ]
    if run_tag:
        lines.append(f"- Run tag: `{run_tag}`")
    lines.extend(
        [
            f"- Dataset: `{dataset_path}`",
            f"- Dataset SHA-256: `{dataset_sha}`",
            f"- Samples: {sample_count}",
            f"- Synthetic augmentation samples: {synthetic_count}",
            f"- Labels: {', '.join(labels)}",
            f"- Max vocab configured: {max_vocab}",
            f"- Min token frequency configured: {min_token_freq}",
            f"- Vocab before pruning: {eval_summary['vocab_size_raw']}",
            f"- Vocab after pruning: {eval_summary['vocab_size_pruned']}",
            f"- Prune target vocab: {prune_target_vocab}",
            f"- Prior uniform mix: {prior_uniform_mix:.2f}",
            f"- Holdout accuracy: {eval_summary['accuracy'] * 100:.2f}% (test size: {eval_summary['test_size']})",
            "",
            f"- Holdout threshold: {min_holdout_accuracy * 100:.2f}%",
            f"- Threshold pass: {'yes' if eval_summary['accuracy'] >= min_holdout_accuracy else 'no'}",
            "",
            "## Travel Design Taxonomy",
            "",
        ]
    )
    for label in labels:
        lines.append(f"- `{label}`: {LABEL_BRIEF.get(label, label)}")

    lines.extend(["", "## Holdout Label Breakdown", "", "| Label | Correct | Total | Accuracy |", "| --- | ---: | ---: | ---: |"])
    for label in labels:
        correct, total = eval_summary["per_label"].get(label, [0, 0])
        acc = (correct / total * 100.0) if total else 0.0
        lines.append(f"| {label} | {correct} | {total} | {acc:.2f}% |")

    lines.extend(["", "## Confusion Matrix (actual -> predicted counts)", ""])
    confusion = eval_summary["confusion"]
    if not confusion:
        lines.append("No confusion matrix available.")
    else:
        for actual in sorted(confusion.keys()):
            pairs = [f"{pred}:{count}" for pred, count in sorted(confusion[actual].items())]
            lines.append(f"- {actual} -> {', '.join(pairs)}")

    lines.extend(
        [
            "",
            "## Notes",
            "",
            "- This model is optimized for low-latency on-device Swift inference.",
            "- Training pipeline is Swift-focused and independent from Rust cloud model lifecycle.",
            "- Pruning is vocabulary-importance-based to reduce model size while retaining high-signal tokens.",
        ]
    )
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def main():
    parser = argparse.ArgumentParser(description="Train Swift local model for Atlas Travel Design taxonomy.")
    parser.add_argument("--dataset", default=str(DEFAULT_DATASET))
    parser.add_argument("--max-vocab", type=int, default=1000)
    parser.add_argument("--prune-target-vocab", type=int, default=800)
    parser.add_argument("--min-token-freq", type=int, default=1)
    parser.add_argument("--ios-output", default=str(DEFAULT_IOS_OUTPUT))
    parser.add_argument("--macos-output", default=str(DEFAULT_MACOS_OUTPUT))
    parser.add_argument("--report-output", default=str(DEFAULT_REPORT_OUTPUT))
    parser.add_argument("--compat-report-output", default=str(DEFAULT_COMPAT_REPORT_OUTPUT))
    parser.add_argument("--artifact-dir", default=str(DEFAULT_ARTIFACT_DIR))
    parser.add_argument("--run-tag", default="")
    parser.add_argument("--min-holdout-accuracy", type=float, default=0.55)
    parser.add_argument("--prior-uniform-mix", type=float, default=0.65)
    parser.add_argument("--min-per-label", type=int, default=48)
    parser.add_argument("--max-per-label", type=int, default=72)
    parser.add_argument("--allow-below-threshold", action="store_true")
    parser.add_argument("--skip-inject", action="store_true")
    args = parser.parse_args()

    dataset_path = Path(args.dataset).expanduser().resolve()
    ios_output = Path(args.ios_output).expanduser().resolve()
    macos_output = Path(args.macos_output).expanduser().resolve()
    report_output = Path(args.report_output).expanduser().resolve()
    compat_report_output = Path(args.compat_report_output).expanduser().resolve()
    artifact_dir = Path(args.artifact_dir).expanduser().resolve()

    dataset_body = dataset_path.read_text(encoding="utf-8")
    dataset_sha = hashlib.sha256(dataset_body.encode("utf-8")).hexdigest()
    rows = parse_dataset(dataset_path)
    if len(rows) < 20:
        raise RuntimeError(f"dataset too small ({len(rows)} rows), need at least 20")

    rows, synthetic_count = add_synthetic(rows)
    rows = rebalance_rows(
        rows,
        min_per_label=max(1, args.min_per_label),
        max_per_label=max(max(1, args.min_per_label), args.max_per_label),
    )
    labels = collect_labels(rows)

    eval_summary = evaluate_model(
        rows=rows,
        labels=labels,
        max_vocab=max(1, args.max_vocab),
        min_token_freq=max(1, args.min_token_freq),
        prune_target_vocab=max(1, args.prune_target_vocab),
        prior_uniform_mix=args.prior_uniform_mix,
    )

    vocab_raw, freq = build_vocabulary(rows, max_vocab=max(1, args.max_vocab), min_token_freq=max(1, args.min_token_freq))
    importance = compute_token_importance(rows, labels, vocab_raw)
    vocabulary = prune_vocabulary(vocab_raw, token_freq=freq, importance=importance, target=max(1, args.prune_target_vocab))
    if not vocabulary:
        raise RuntimeError("pruned vocabulary is empty")

    log_priors, log_likelihoods = train_weights(rows, labels, vocabulary, prior_uniform_mix=args.prior_uniform_mix)
    keyword_hints = collect_keyword_hints(rows, labels)
    next_actions = collect_next_actions(rows, labels)
    label_briefs = [LABEL_BRIEF.get(label, label.replace("_", " ")) for label in labels]
    keyword_bonus = 2.4

    now = dt.datetime.now(dt.timezone.utc)
    run_suffix = f"-{re.sub(r'[^a-zA-Z0-9_-]+', '-', args.run_tag).strip('-')}" if args.run_tag else ""
    run_id = now.strftime("%Y%m%dT%H%M%SZ") + run_suffix
    model_name = f"atlas-swift-travel-design-v1-{run_id}"

    model = {
        "schema_version": 1,
        "model_name": model_name,
        "trained_at_utc": now.isoformat(),
        "sample_count": len(rows),
        "labels": labels,
        "vocabulary": vocabulary,
        "log_priors": log_priors,
        "log_likelihoods": log_likelihoods,
        "next_actions": next_actions,
        "label_briefs": label_briefs,
        "keyword_hints": keyword_hints,
        "keyword_bonus": keyword_bonus,
    }
    model_json = json.dumps(model, ensure_ascii=False, separators=(",", ":"))

    run_dir = artifact_dir / run_id
    run_dir.mkdir(parents=True, exist_ok=True)
    (run_dir / "model.json").write_text(json.dumps(model, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
    (run_dir / "metrics.json").write_text(json.dumps(eval_summary, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
    manifest = {
        "run_id": run_id,
        "generated_at_utc": now.isoformat(),
        "dataset_path": str(dataset_path),
        "dataset_sha256": dataset_sha,
        "samples_total": len(rows),
        "samples_synthetic": synthetic_count,
        "labels": labels,
        "max_vocab": args.max_vocab,
        "min_token_freq": args.min_token_freq,
        "prune_target_vocab": args.prune_target_vocab,
        "prior_uniform_mix": args.prior_uniform_mix,
        "vocab_size_raw": len(vocab_raw),
        "vocab_size_pruned": len(vocabulary),
        "holdout_accuracy": eval_summary["accuracy"],
        "holdout_size": eval_summary["test_size"],
        "threshold_passed": eval_summary["accuracy"] >= args.min_holdout_accuracy,
        "model_name": model_name,
    }
    (run_dir / "manifest.json").write_text(json.dumps(manifest, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
    (artifact_dir / "latest.json").write_text(
        json.dumps(
            {
                "run_id": run_id,
                "generated_at_utc": now.isoformat(),
                "manifest_path": str(run_dir / "manifest.json"),
                "model_path": str(run_dir / "model.json"),
                "holdout_accuracy": eval_summary["accuracy"],
            },
            ensure_ascii=False,
            indent=2,
        )
        + "\n",
        encoding="utf-8",
    )

    write_report(
        report_path=report_output,
        run_id=run_id,
        run_tag=args.run_tag,
        dataset_path=dataset_path,
        dataset_sha=dataset_sha,
        sample_count=len(rows),
        synthetic_count=synthetic_count,
        labels=labels,
        max_vocab=args.max_vocab,
        min_token_freq=args.min_token_freq,
        prune_target_vocab=args.prune_target_vocab,
        prior_uniform_mix=args.prior_uniform_mix,
        eval_summary=eval_summary,
        min_holdout_accuracy=args.min_holdout_accuracy,
    )
    compat_report_output.parent.mkdir(parents=True, exist_ok=True)
    compat_report_output.write_text(report_output.read_text(encoding="utf-8"), encoding="utf-8")

    threshold_passed = eval_summary["accuracy"] >= args.min_holdout_accuracy
    if not threshold_passed and not args.allow_below_threshold:
        raise RuntimeError(
            f"holdout accuracy {eval_summary['accuracy'] * 100:.2f}% below threshold {args.min_holdout_accuracy * 100:.2f}%"
        )

    if not args.skip_inject:
        inject_model_block(ios_output, model_json)
        inject_model_block(macos_output, model_json)

    print(
        "trained swift travel-design model:"
        f" run_id={run_id}"
        f" samples={len(rows)}"
        f" labels={len(labels)}"
        f" vocab_raw={len(vocab_raw)}"
        f" vocab_pruned={len(vocabulary)}"
        f" eval_acc={eval_summary['accuracy'] * 100:.2f}%"
        f" threshold_passed={str(threshold_passed).lower()}"
    )
    if not args.skip_inject:
        print(f"updated {ios_output}")
        print(f"updated {macos_output}")
    print(f"wrote {report_output}")
    print(f"artifacts {run_dir}")


if __name__ == "__main__":
    main()
